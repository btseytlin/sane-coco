{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from sane_coco.dataset import COCODataset\n",
    "from sane_coco.metrics import MeanAveragePrecision\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def ultralytics_batch_detect(\n",
    "    image_paths: List[str], \n",
    "    batch_size: int = 16, \n",
    "    conf: float = 0.25\n",
    ") -> List[List[Dict]]:\n",
    "    model = YOLO('yolov8n.pt', verbose=False)\n",
    "    model.to('cpu')\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(image_paths), batch_size)):\n",
    "        batch = image_paths[i:i + batch_size]\n",
    "        preds = model(batch, conf=conf, verbose=False)\n",
    "        batch_results = [\n",
    "            [\n",
    "                {'bbox': box.xyxy[0].tolist(), \n",
    "                 'conf': float(box.conf), \n",
    "                 'class': int(box.cls)}\n",
    "                for box in pred.boxes\n",
    "            ]\n",
    "            for pred in preds\n",
    "        ]\n",
    "        results.extend(batch_results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_classes = {\n",
    "    0: \"person\",\n",
    "    1: \"bicycle\", \n",
    "    2: \"car\",\n",
    "    3: \"motorcycle\",\n",
    "    4: \"airplane\",\n",
    "    5: \"bus\",\n",
    "    6: \"train\",\n",
    "    7: \"truck\", \n",
    "    8: \"boat\",\n",
    "    9: \"traffic light\",\n",
    "    10: \"fire hydrant\",\n",
    "    11: \"stop sign\",\n",
    "    12: \"parking meter\",\n",
    "    13: \"bench\",\n",
    "    14: \"bird\",\n",
    "    15: \"cat\",\n",
    "    16: \"dog\",\n",
    "    17: \"horse\",\n",
    "    18: \"sheep\",\n",
    "    19: \"cow\",\n",
    "    20: \"elephant\",\n",
    "    21: \"bear\",\n",
    "    22: \"zebra\",\n",
    "    23: \"giraffe\",\n",
    "    24: \"backpack\",\n",
    "    25: \"umbrella\",\n",
    "    26: \"handbag\",\n",
    "    27: \"tie\",\n",
    "    28: \"suitcase\",\n",
    "    29: \"frisbee\",\n",
    "    30: \"skis\",\n",
    "    31: \"snowboard\",\n",
    "    32: \"sports ball\",\n",
    "    33: \"kite\",\n",
    "    34: \"baseball bat\",\n",
    "    35: \"baseball glove\",\n",
    "    36: \"skateboard\",\n",
    "    37: \"surfboard\",\n",
    "    38: \"tennis racket\",\n",
    "    39: \"bottle\",\n",
    "    40: \"wine glass\",\n",
    "    41: \"cup\",\n",
    "    42: \"fork\",\n",
    "    43: \"knife\",\n",
    "    44: \"spoon\",\n",
    "    45: \"bowl\",\n",
    "    46: \"banana\",\n",
    "    47: \"apple\",\n",
    "    48: \"sandwich\",\n",
    "    49: \"orange\",\n",
    "    50: \"broccoli\",\n",
    "    51: \"carrot\",\n",
    "    52: \"hot dog\",\n",
    "    53: \"pizza\",\n",
    "    54: \"donut\",\n",
    "    55: \"cake\",\n",
    "    56: \"chair\",\n",
    "    57: \"couch\",\n",
    "    58: \"potted plant\",\n",
    "    59: \"bed\",\n",
    "    60: \"dining table\",\n",
    "    61: \"toilet\",\n",
    "    62: \"tv\",\n",
    "    63: \"laptop\",\n",
    "    64: \"mouse\",\n",
    "    65: \"remote\",\n",
    "    66: \"keyboard\",\n",
    "    67: \"cell phone\",\n",
    "    68: \"microwave\",\n",
    "    69: \"oven\",\n",
    "    70: \"toaster\",\n",
    "    71: \"sink\",\n",
    "    72: \"refrigerator\",\n",
    "    73: \"book\",\n",
    "    74: \"clock\",\n",
    "    75: \"vase\",\n",
    "    76: \"scissors\",\n",
    "    77: \"teddy bear\",\n",
    "    78: \"hair drier\",\n",
    "    79: \"toothbrush\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:27<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "images_dir = 'COCO/DIR/val2017'\n",
    "image_filenames = os.listdir(images_dir)\n",
    "image_paths = [f'{images_dir}/{image}' for image in image_filenames]\n",
    "results = ultralytics_batch_detect(image_paths, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval using pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_fpath = '/Users/boris/Documents/datasets/coco/annotations/instances_val2017.json'\n",
    "\n",
    "predictions_fpath = './predictions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.29s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=3.89s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.57s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
      "MAP@0.5|0.95: 0.01035477744363631\n",
      "MAP@0.5: 0.030815749670804925\n"
     ]
    }
   ],
   "source": [
    "anno = COCO(str(annotations_fpath)) \n",
    "\n",
    "yolo_classes_reverse = {v: k for k, v in yolo_classes.items()}\n",
    "yolo_id_to_coco_id = {}\n",
    "for cat in anno.cats:\n",
    "    coco_id = anno.cats[cat]['id']\n",
    "    name = anno.cats[cat]['name']\n",
    "    yolo_id = yolo_classes_reverse[name]\n",
    "    yolo_id_to_coco_id[yolo_id] = coco_id\n",
    "\n",
    "predictions = []\n",
    "for i, (image_filename, result) in enumerate(zip(image_filenames, results)):\n",
    "    image_id = int(Path(image_filename).stem)\n",
    "    for detection in result:\n",
    "        predictions.append({\n",
    "            'image_id': image_id,\n",
    "            'bbox': detection['bbox'],\n",
    "            'score': detection['conf'],\n",
    "            'category_id': yolo_id_to_coco_id[detection['class']]\n",
    "        })\n",
    "\n",
    "with open(predictions_fpath, 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "pred = anno.loadRes(str(predictions_fpath))\n",
    "\n",
    "val = COCOeval(anno, pred, \"bbox\")\n",
    "val.params.imgIds = [int(Path(x).stem) for x in image_filenames]\n",
    "val.evaluate()\n",
    "val.accumulate()\n",
    "val.summarize()\n",
    "stats = {}\n",
    "stats[\"map_50_95\"] = val.stats[0]\n",
    "stats[\"map_50\"] = val.stats[1]\n",
    "\n",
    "print('MAP@0.5|0.95:', stats['map_50_95'])\n",
    "print('MAP@0.5:', stats['map_50'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval using sane coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotations_fpath, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "dataset = COCODataset.from_dict(annotations)\n",
    "annotations = dataset.get_annotation_dicts()\n",
    "\n",
    "included_images = [\n",
    "    i for i in range(len(dataset.images))\n",
    "    if dataset.images[i].id in [int(Path(x).stem) for x in image_filenames]\n",
    "]\n",
    "included_image_ids = [dataset.images[i].id for i in included_images]\n",
    "included_annotations = [annotations[i] for i in included_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image_ids = [int(Path(x).stem) for x in image_filenames]\n",
    "predictions = {}\n",
    "for i, (image_id, result) in enumerate(zip(predicted_image_ids, results)):\n",
    "    image_predictions = []\n",
    "    for detection in result:\n",
    "        category_id = yolo_id_to_coco_id[detection['class']]\n",
    "        category = dataset.get_category_by_id(category_id)\n",
    "\n",
    "        image_predictions.append({\n",
    "            'score': detection['conf'],\n",
    "            'category': category.name,\n",
    "            'bbox': detection['bbox'],\n",
    "        })\n",
    "    predictions[image_id] = image_predictions\n",
    "\n",
    "predictions = [predictions[i] for i in included_image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@0.5|0.95: 0.008281212656477256\n",
      "MAP@0.5: 0.024394058646580518\n"
     ]
    }
   ],
   "source": [
    "metrics = MeanAveragePrecision()\n",
    "metrics.update(included_annotations, predictions)\n",
    "stats = metrics.compute()\n",
    "print('MAP@0.5|0.95:', stats['map'])\n",
    "print('MAP@0.5:', stats['ap'][0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
