{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from sane_coco.dataset import COCODataset\n",
    "from sane_coco.metrics import MeanAveragePrecision\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def ultralytics_batch_detect(\n",
    "    image_paths: List[str], \n",
    "    batch_size: int = 16, \n",
    "    conf: float = 0.25\n",
    ") -> List[List[Dict]]:\n",
    "    model = YOLO('yolov8n.pt', verbose=False)\n",
    "    model.to('cpu')\n",
    "    results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(image_paths), batch_size)):\n",
    "        batch = image_paths[i:i + batch_size]\n",
    "        preds = model(batch, conf=conf, verbose=False)\n",
    "        batch_results = [\n",
    "            [\n",
    "                {'bbox': box.xyxy[0].tolist(), \n",
    "                 'conf': float(box.conf), \n",
    "                 'class': int(box.cls)}\n",
    "                for box in pred.boxes\n",
    "            ]\n",
    "            for pred in preds\n",
    "        ]\n",
    "        results.extend(batch_results)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_TO_COCO = {\n",
    "    0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 13, 12: 14, \n",
    "    13: 15, 14: 16, 15: 17, 16: 18, 17: 19, 18: 20, 19: 21, 20: 22, 21: 23, 22: 24, 23: 25,\n",
    "    24: 27, 25: 28, 26: 31, 27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39,\n",
    "    35: 40, 36: 41, 37: 42, 38: 43, 39: 44, 40: 46, 41: 47, 42: 48, 43: 49, 44: 50, 45: 51,\n",
    "    46: 52, 47: 53, 48: 54, 49: 55, 50: 56, 51: 57, 52: 58, 53: 59, 54: 60, 55: 61, 56: 62,\n",
    "    57: 63, 58: 64, 59: 65, 60: 67, 61: 70, 62: 72, 63: 73, 64: 74, 65: 75, 66: 76, 67: 77,\n",
    "    68: 78, 69: 79, 70: 80, 71: 81, 72: 82, 73: 84, 74: 85, 75: 86, 76: 87, 77: 88, 78: 89,\n",
    "    79: 90\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [04:27<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "images_dir = 'COCO/DIR/val2017'\n",
    "image_filenames = os.listdir(images_dir)\n",
    "image_paths = [f'{images_dir}/{image}' for image in image_filenames]\n",
    "results = ultralytics_batch_detect(image_paths, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval using pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_fpath = '/Users/boris/Documents/datasets/coco/annotations/instances_val2017.json'\n",
    "\n",
    "predictions_fpath = './predictions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.21s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=4.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.57s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.031\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.036\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
      "MAP@0.5|0.95: 0.01035477744363631\n",
      "MAP@0.5: 0.030815749670804925\n"
     ]
    }
   ],
   "source": [
    "anno = COCO(str(annotations_fpath)) \n",
    "\n",
    "predictions = []\n",
    "for i, (image_filename, result) in enumerate(zip(image_filenames, results)):\n",
    "    image_id = int(Path(image_filename).stem)\n",
    "    for detection in result:\n",
    "        predictions.append({\n",
    "            'image_id': image_id,\n",
    "            'bbox': detection['bbox'],\n",
    "            'score': detection['conf'],\n",
    "            'category_id': YOLO_TO_COCO[detection['class']]\n",
    "        })\n",
    "\n",
    "with open(predictions_fpath, 'w') as f:\n",
    "    json.dump(predictions, f)\n",
    "\n",
    "pred = anno.loadRes(str(predictions_fpath))\n",
    "\n",
    "val = COCOeval(anno, pred, \"bbox\")\n",
    "val.params.imgIds = [int(Path(x).stem) for x in image_filenames]\n",
    "val.evaluate()\n",
    "val.accumulate()\n",
    "val.summarize()\n",
    "stats = {}\n",
    "stats[\"map_50_95\"] = val.stats[0]\n",
    "stats[\"map_50\"] = val.stats[1]\n",
    "\n",
    "print('MAP@0.5|0.95:', stats['map_50_95'])\n",
    "print('MAP@0.5:', stats['map_50'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval using sane coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(annotations_fpath, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "dataset = COCODataset.from_dict(annotations)\n",
    "annotations = dataset.get_annotation_dicts()\n",
    "\n",
    "included_images = [\n",
    "    i for i in range(len(dataset.images))\n",
    "    if dataset.images[i].id in [int(Path(x).stem) for x in image_filenames]\n",
    "]\n",
    "included_image_ids = [dataset.images[i].id for i in included_images]\n",
    "included_annotations = [annotations[i] for i in included_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_image_ids = [int(Path(x).stem) for x in image_filenames]\n",
    "predictions = {}\n",
    "for i, (image_id, result) in enumerate(zip(predicted_image_ids, results)):\n",
    "    image_predictions = []\n",
    "    for detection in result:\n",
    "        category_id = YOLO_TO_COCO[detection['class']]\n",
    "        category = dataset.get_category_by_id(category_id)\n",
    "\n",
    "        image_predictions.append({\n",
    "            'score': detection['conf'],\n",
    "            'category': category.name,\n",
    "            'bbox': detection['bbox'],\n",
    "        })\n",
    "    predictions[image_id] = image_predictions\n",
    "\n",
    "predictions = [predictions[i] for i in included_image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@0.5|0.95: 0.008281212656477256\n",
      "MAP@0.5: 0.024394058646580518\n"
     ]
    }
   ],
   "source": [
    "metrics = MeanAveragePrecision()\n",
    "metrics.update(included_annotations, predictions)\n",
    "stats = metrics.compute()\n",
    "print('MAP@0.5|0.95:', stats['map'])\n",
    "print('MAP@0.5:', stats['ap'][0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
